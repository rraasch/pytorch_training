{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6Tsif7xsFTb73O5IOT2rQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rraasch/pytorch_training/blob/main/pytorch_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qTsQsTF2GmE"
      },
      "outputs": [],
      "source": [
        "#pytorch learning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "id": "CVtI4_xN2Ikf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "CEUO2Dba2XwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Create datasets for training & validation, download if necessary\n",
        "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
        "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k46phNyn2fPa",
        "outputId": "c58ea2c5-b39e-4be0-fdd4-a3676f76ab1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.5,), std=(0.5,))\n",
            "           )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders for our datasets; shuffle for training, not for validation\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
        "\n",
        "# Class labels\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "# Report split sizes\n",
        "print('Training set has {} instances'.format(len(training_set)))\n",
        "print('Validation set has {} instances'.format(len(validation_set)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BzxYlyr2s12",
        "outputId": "d2a3a8f5-bbd1-4661-9f11-cc77623dc19e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set has 60000 instances\n",
            "Validation set has 10000 instances\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Helper function for inline image display\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Create a grid from the images and show them\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "matplotlib_imshow(img_grid, one_channel=True)\n",
        "print('  '.join(classes[labels[j]] for j in range(4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "kYn3nqkR3MhP",
        "outputId": "f982f005-2d10-498d-d323-75a05c134adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shirt  Shirt  Shirt  Coat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoBklEQVR4nO3de3RU1dkG8CcBknBLIIEkxBCNioICgkEw4oVqlFKWl4KtUhSqrMVSAwXSqkRFV602irVSFcG2VrSKKFW00CrFoKFoCBCgcjMgIARCAoi5cAuRnO+PlvnYzxmzM5lAziTPby3W6jtz5szJPmfG3dnved8wx3EciIiIiHhAeFMfgIiIiMhJmpiIiIiIZ2hiIiIiIp6hiYmIiIh4hiYmIiIi4hmamIiIiIhnaGIiIiIinqGJiYiIiHiGJiYiIiLiGZqYiIiIiGectonJzJkzcc455yAqKgqDBg3CypUrT9dbiYiISDMRdjp65bz99tsYM2YMZs+ejUGDBmHGjBmYP38+ioqKEB8fX+dra2trUVJSgo4dOyIsLKyxD01EREROA8dxUFVVhaSkJISHN/x3j9MyMRk0aBAuu+wyvPjiiwD+O9no3r07Jk6ciKlTp9b52t27d6N79+6NfUgiIiJyBhQXFyM5ObnBr2/diMcCADh+/DgKCwuRnZ3teyw8PBwZGRnIz893bV9dXY3q6mpffHKe9MQTTyAqKqqxD09EREROg2PHjuGRRx5Bx44dg9pPo09MDhw4gBMnTiAhIcF4PCEhAV9++aVr+5ycHPz61792PR4VFYW2bds29uGJiIjIaRRsGkaT35WTnZ2NiooK37/i4uKmPiQRERFpIo3+i0mXLl3QqlUrlJWVGY+XlZUhMTHRtX1kZCQiIyMb+zBEREQkBDX6LyYRERFIS0tDbm6u77Ha2lrk5uYiPT29sd9OREREmpFG/8UEALKysjB27FgMGDAAAwcOxIwZM3D48GHcddddp+PtREREpJk4LROT2267Dfv378ejjz6K0tJS9OvXDx999JErIbah7rvvvkbZz+m0c+dOI+b6LY2d2Ltt2zYjPvvss424devTcqqD8tJLL9X5vBfP81//+lcj5r+Bz2u7du2MmLPV+/XrZ8S7d+824o0bNxrx/v37jfi7774z4szMTCMeM2aMEUdHR+NMC8XzHKjy8vI6nz927JgRHzlyxIjbtGljxLaSCVzlwQs1n5rjeX7iiSeM+OuvvzbiX/7yl0Z88OBBI54wYYIRv/XWW0bcs2fPII/wzLOd58Zw2v5rNWHCBNdJEREREalLk9+VIyIiInKSJiYiIiLiGd5LPPAoXst/+OGHjfi2224z4pKSEiPmZS3ORbj88suNODY21og3bdpkxJs3bzbiq666yoiffvppI37jjTeM+MorrwS74oorXI81Z/5q5gwfPtyIOXfgwIEDRsw5I7zWz7fNc/+Io0ePGvH27duNeP369UbcqVMnI+brkte8uQWEv15VXbt2NeKCggLXNlI3/nytWLHCiDnX6NRq14A7dyEvL6/O9/NCTkkoOnHihBHz543zYJYvX27EnCv0yiuvGDF/vmtra424V69eRvzMM8/U+f583dj46zATiteKfjERERERz9DERERERDxDExMRERHxDOWY1BPXAeF6EHx/Oq8dcl0TzjnhtcsbbrjBiG+66aY633/GjBlGzA0TCwsLjZhzFYDmn2PC+SJcQwQAampqjJhzfbgWD2/Pa8w9evQwYj7Pp1ZIBtz1LM4666w6X8/v1759eyPm65brZwDAypUrjfjqq6824mXLlrle09zxeT106JARf/vtt0bMOWZ/+ctf6tzf3r17jXjOnDlGzLlHe/bsMeIuXboYcYcOHYzYi3WLzrTFixe7Hps9e7YR8/fohRdeaMT8eeHv8XfeeceIx40bZ8ScS8i5gJWVlUY8fvx4I05LSzPiSZMmGTF//puL5vlXiYiISEjSxEREREQ8QxMTERER8QwtRDbQqFGjjJjrR/D97dzDZPDgwUb82WefGTHXGeH77++44w4j5jXpP//5z0bMuRLcQ6UleOyxx4z4+PHjrm24zgfXCeGY8Xni3ASuKcDnhesQcG4Cv5635+Pj5/2tSXO+gq3vS6jhMQSAffv2GXFVVZUR87hx3RHO5Zk/f74R33///UY8evRoI7733nuNmHOJOEcsLi7OiLlnEsecqwQA3bp1M+LIyEjXNl5m6w/E5/DZZ5917YO/V3kfXDekb9++RlxaWmrEnFt4wQUXGDHn7XFOC9c54fP2r3/9y4hXrVplxHPnzjXiUKxZ4o9+MRERERHP0MREREREPEMTExEREfEMTUxERETEM5T82kCc5MhJVdOnTzfiJUuWGPHEiRONeNiwYXXun5vH/eY3vzHijz/+2Ig5UYwL93AyHwBERUW5HmtO7rzzTiN+/fXXra+xJY9y8honn9mS0ThZtVWrVnXGfDz+mnbVhfcHuBN033vvvYD26TV8TrjhJeAuQMbNGPl523kcMWKEEXMBQy7MxQXROHGTzxMn2/Lz9UnS5oaSnHDr79rwEts5ePnll42YixsC7uT2HTt2GPE333xjxDxGfN4iIiLqfE8u0MZJ15yAz9/B/N8VPof//Oc/jfhHP/oRmC1p2Iv0i4mIiIh4hiYmIiIi4hmamIiIiIhnKMekgXjdjgvnJCYmGjGvMXNOCa9FctErXlscMmSIEfOaNq9Vcs5KKKwzNjZuiMXr9oA9Z4THkdmetxVIs+HXc14AHz8fj7/mblxUKjU1NaBj8hougsWN1AB3TkmgOLeAc4+4SB1/PzAutMc4Z8R2Xv2dZy6odvjw4YCO0es4D89fAUVugslF57hQJX/e/BXrOxXnCvF55eaNXFCtc+fORszX1cGDB4343XffNWJ/OSah+F2vX0xERETEMzQxEREREc/QxEREREQ8QzkmDcRr+9u3bzfirl27GnGfPn2MmO9PX79+vRH/7Gc/M+IFCxYYMTeX4jXtrVu3GjHfP+/1mgWng62BHgDs3r3biHnd3V8TvLqe51wA27hzjgjHvH9eo+ZcBF4T57wCAKioqAjoGL2Oa/T4O2c8Tv5yMk7F55HzF/g9+HnOIeNcAj5PvD9b/RzbdeJvm1DMPTgVjzHXIPGXQ7Zr1y4j7t27txFzTR8+b7Y8Ha5zwmPO1xnnd/Fnkb/X+Xg4Z6a50C8mIiIi4hmamIiIiIhnaGIiIiIinqEckwbie+b5/nTGtRR4jZtzRhYtWmTEZ599thHzGnL37t2NeOXKlUbM66+89tkS3X///a7HHn74YSPm88Tr1v56kpzK1nOFn+e6JrbzxPkgnAvBdRn85Y+8//77db5HqOG/2V9tGf788Hmw9Shith5Jtlwg2/4YHx8fP9fTANzj4K++SyiprKw04k2bNhlxRkaG6zWca8d9lBISEoyYczi4fg2P6f79++t8nnOJOGeEc1b4e5vz4vg8c50Tf68JBfrFRERERDxDExMRERHxjIAnJsuWLcONN96IpKQkhIWFuX4GdhwHjz76KLp164a2bdsiIyPDdeuqiIiIiD8B55gcPnwYl1xyCe6++26MGDHC9fz06dPx/PPP47XXXkNqaiqmTZuGoUOHYtOmTa7+LaFs27ZtRsy5B7z2l5KSYsQPPfSQEXN/Eu6V88EHHxjxhRdeaMTDhw834l69ehkxr6nz/fJA8P1DQs2dd97peiw9Pd2IBw4caMTx8fFGzGvGtl4bfB5suQz8es5N4O15DZxzn1577TUw7rsU6mw1RQD3WjzXHbJ9VwVa68XW48jWy8pW14SvC74OAXeuAb9noLVdmhr3D+PvXH+5RdxTzN+1cSr+fJWUlBgxjynXMfGX63Mq/j7huibFxcVGzHVUOK+Gcx/9HWMoCPjKGzZsmKsB3UmO42DGjBl45JFHcPPNNwMAXn/9dSQkJOD999/H7bffHtzRioiISLPWqDkmO3bsQGlpqZENHRMTg0GDBiE/P9/va6qrq1FZWWn8ExERkZapUScmJ9uN8y1XCQkJrlbkJ+Xk5CAmJsb3j297FRERkZajyRcRs7OzkZWV5YsrKytDYnLSo0cPI16zZo0Rn3vuuUYcExNjxLzux/09uJfO2rVrjZjHiOucfPbZZ0bMuRC8Vin/df755xsx1xHhNVzOReB1bVuPE17X5+d5jdvfuvmp+DriXKVbb721ztc3B7xO/+2337q24fPC2/Dav+08cc4I17/g88bHyPj9+Hj5uuP/48f1Mfztg/v1hFqOCdcgYf7ygPgXef6buTcNjwGPO+cC8eePv3c5j2/Pnj1GbKuTwjg3kfcHABdccEGd+/CiRv3FJDExEYA7KamsrMz3HIuMjER0dLTxT0RERFqmRp2YpKamIjExEbm5ub7HKisrUVBQ4LrbQURERIQF/FvdoUOH8NVXX/niHTt2YN26dYiNjUVKSgomT56MJ554Aj169PDdLpyUlIRbbrmlMY9bREREmqGAJyarV6/GD37wA198Mj9k7NixmDNnDh544AEcPnwY48ePR3l5Oa688kp89NFHzaqGCeDuabBgwQIjvvTSS4142bJlRsx1FHhN+/PPPzdi7rXBz/Oa96pVq+p8Xjkm9cO5RF9//bURc78RXse39TyxsfVg4XV0XiMPhXytYHEtCs4j8FfHgceJc0J4nG05WoH23uHcBs4lsG3P36f8vL9ePDxOvE2gtVma2s6dO4344osvNuJPP/3U9Roe5+uvv96I+bxxThnf2ME5HTymSUlJRszXFecCcY4JFzDNzs42Ys5Z4f8uADD+ex0qAp6YDBkypM6GVmFhYXj88cfx+OOPB3VgIiIi0vKoV46IiIh4hiYmIiIi4hnevlHdw7i3BueccE8FXpvkXha89llQUFDn63n/fDy83MZr5JwbIf5x7wtbLgHj88C5PsxW94TZciG4vk1zxH8znxNetweAb775xoj588D7sJ0XWy4Q54jx87acFMav51wDzjEDgGuuuabO9wg2H+pMs/Un4744ALBw4UIj5j5Rtnox3LuGy1twzgjHfK1yfSv+vrHVPeK6Kf7qmIQi/WIiIiIinqGJiYiIiHiGJiYiIiLiGcoxaSBe0+X1WV7/5LolvJbJcXJyshHz2iSvD3OvHt4f5zrUdcu3/D+uA7Jhw4Y6t7f1yrFtz+fV1jvHFnMuRXPE6+y8Tu9v3Z3HnXPEOOfDlisU6OeLvy9s2/P7cc4Kfz9wvR3AnU/Bf6O/2idexjVGuK7JVVdd5XoN1zqx9bri82LLAeGcE36eezLxfyf4/fv162fE/Hnm7UPtHH4f/WIiIiIinqGJiYiIiHiGJiYiIiLiGcoxaSBey+O1SF6z5jVfvsee1yL5/nfOPbCto3NuQ0VFhRHzWifgrpUi7hoYgdYhCZRt/7btOfegJfREsuVT+as1s3XrViPmGh+2nke2mh/8PNct4uuKj9GW68DfB5xfsW/fPtcx8bXB+D29jr/TOF/EXz5Yz549jZjHnXN1Dh06ZMRxcXFGzN/z3I+Ic0i4Xg73aOLjGTRoEOrCf7O/887H5K+uj9foFxMRERHxDE1MRERExDM0MRERERHPUI5JA23fvt2IeX2W1wo5J4TXnJmtnoWt/gWvJ/P7bdu2zfWeyjFx2717txHb8hmCFej++brg9WN/a842/J6h1kOFcW0JANi7d68Rx8bGGjGPa6A5J7acERv+PHOegO34ODeiPryeY8J5fbZ+RpwvAgBnnXWWEfO4ct4K54hwbxvOEeE6I/w853xxriH/d4L3V15ebsScW8g1fQCgrKzMiLk2kxfpFxMRERHxDE1MRERExDM0MRERERHP0MREREREPEPJrw30+eefG7G/Ik6nCrRwFrMlpnGyHCcwclLk8uXLXfu44oorGnh0oaEhSZ2cQMfj2NjJr3yebdcNvz8n1+3fv7/O/QP2RGt+3mtsDTG5CBXgbnppK6RnK5zHiZm2ZHhmK5TH54DfjxMauWko4E7s5KTgYIsDnm5czIwTfDmBmW9QANzNV9u1a2fExcXFRszXBX+eeHtuvsrvV1JSYsS2QpqcbMvfR5wsGwqJrfXh7StRREREWhRNTERERMQzNDERERERz1COSQN99dVXRsxrkbzGHGgTMNu6uS0PgN+f15P//e9/u97zgQceqPOYQl19ckx4Gz7PnMNhO8+B5qDw9oHGfB1UVVUZMa+RA0BiYqIRez3XgPGY8xhUVla6XsOF82zNDm2NAfk9+Zg4N4A/v7brhnNO+Hku1OWvSSePA7+n1887Hz9/9ri4GOecAO5x4+aH/D1ua8bYtWtXIz5w4IAR8+ePmwByATa+TrgAHOes8N/sL6+G81hCgbevRBEREWlRNDERERERz9DERERERDxDOSYNtGXLFiO25R7Y1qB5e9taJ69R81okr6W2bdvWiHNzc9HS1Cffg5tmca0EXsu3nTdb/RlbboHtvHPMuQ9c78LfeR89enSdxxhq+Bz4a2zGzdy4HgTnBjDbtWTLIePX83linGPC1xXXaklJSXHtg/MTbO/pNfxZ5JwYzkHp0qWLax/8PcjXBp+X+Ph4I+ZaKpxTwueBj5mvM9vx8DnimJv6de7cGawhDR2bmn4xEREREc8IaGKSk5ODyy67DB07dkR8fDxuueUWFBUVGdscO3YMmZmZiIuLQ4cOHTBy5EhX22URERERfwKamOTl5SEzMxMrVqzAkiVLUFNTgxtuuMH4eWvKlClYuHAh5s+fj7y8PJSUlGDEiBGNfuAiIiLS/ASUY/LRRx8Z8Zw5cxAfH4/CwkJcffXVqKiowCuvvIK5c+fi2muvBQC8+uqr6NWrF1asWIHLL7+88Y68iW3bts2IuUdBsL1x+PW2NW3bmjXnwDSXngqBqE9vnM2bNxsx5+7YepbYckpYoOfVVnvCdt0tXrzY9RjnmNRnnLzE1tfG3znhfAv+fHCvGc7xsB0DXxd8TLYxttXH4euQj/+8885z7dNWAyPU6pjYejj5+yzY8mp4HPk9d+zYYcTdunUzYq4fwzknXDeFX8/fN3yO+BzyGHBdFADYs2ePEaelpbm28ZqgrsSTTaFOFrIpLCxETU0NMjIyfNv07NkTKSkpyM/PD+atREREpAVo8F05tbW1mDx5MgYPHozevXsDAEpLSxEREeG6cyEhIQGlpaV+91NdXW3MCv1VaRQREZGWocG/mGRmZmLDhg2YN29eUAeQk5ODmJgY37+WuMQgIiIi/9WgX0wmTJiARYsWYdmyZUhOTvY9npiYiOPHj6O8vNz41aSsrMzVj+Ok7OxsZGVl+eLKykpPTk547Y/XBnltktcyA12359wCXi8NtBcP17c4uQx3Kr4nnn/5CnX1OQdbt241YluOh63OSKA5JLY6JbaeSHydcp2EvXv31nk8oYj7i/C6vr+aJO3btw/qPW3nIdDPuy1fgvF1w+/P30+AO4fEVlvJa7jGENcUadeunRGnpqa69sG1TfjzwjkaPEbcG8dWd4Tr5XDuD++fc1T4ePg7mb+z+/Xrh+YgoF9MHMfBhAkTsGDBAixdutR14tPS0tCmTRujiFNRURF27dqF9PR0v/uMjIxEdHS08U9ERERapoB+McnMzMTcuXPxwQcfoGPHjr68kZiYGLRt2xYxMTEYN24csrKyEBsbi+joaEycOBHp6enN6o4cEREROT0CmpjMmjULADBkyBDj8VdffRU///nPAQDPPfccwsPDMXLkSFRXV2Po0KF46aWXGuVgRUREpHkLaGJSn14jUVFRmDlzJmbOnNngg/IiXt/ktUVe36zPWNWFX2+LbbUb+Hl/x8e1G5pbjkl97Nq1y4i5foUtF8CWaxBojxVbTyWOef98/JxD0xzwtc2xvxwT/rwG+h628xhofRkWaL0afj4mJsa1T67B0bdvXyP2eu8czgfhMeCeMO+++65rH/w9HhcXZ8T8eeLvA84l5OuIc0JKSkqMmD+PnOvH++fXc64mX9v+7n7lfj6hwNsVdURERKRF0cREREREPEMTExEREfGMBld+bWl4/XLLli1GzP0HAl2vta1Z89onr69yzgtvz7kRvHYJAPv37zfic889t85jCjX1qdOwfv16I+b6L8HmDgXL1jOFrwuuY8J1DwD3eedaDV5ny6fi3ATAfw7GqQLN9eHzYMtFCrSmiK3eDe/PX28frvvB23g9x4SvUy4tERERYcT+ajWtXr3aiPl7k8ed98m4ho7tvNiuI8bn7GQPupM4LzApKcm1D1ufJy/SLyYiIiLiGZqYiIiIiGdoYiIiIiKeoRyTeuIeBsy2Jh2sQOtf8NpmfXxfB+iWhNeceY3Z1gvH1kPFVo+G2a4j2/44R4ZzpQCguLjYiEMtx8SWn3HkyBHXa07t8eXvNbbeVLbcAX49d03n3J9g693Up+8N50ME2p+nqfEYdu7c2Yi5hkhKSoprH9u3bzdiPg/8eeHzyOPKeTm8vS2/w5ZzcvTo0Tpjrk1z6aWXut6D81RCgX4xEREREc/QxEREREQ8QxMTERER8QzlmNTThg0bjNjf+uWpbGvEga4h2+qYMFv9jYSEBNdruI9ES8S9J2xr/8H2xmGB5qDYrgN+vb/cgy+++MKI/a1ThxLOneDcBMA+rpwbEGiuD+c7tG/fPqDXM1vuEuc69OrVy7WPffv2GTHXd2lIXlpT4u+wbdu2GfE//vEP12uuvvpqI167dq0Rcz4GXzucr8T5Wdx7JzY21ojLysqMmK8TzgM62Rz3pJ07dxrxZ599ZsT8vQ/4r13kdaF1JYqIiEizpomJiIiIeIYmJiIiIuIZyjGpJ16n4zVjXgMONLfAdn88s62B23qm8P3wALBx40brcTZ3nGNi60Vj63XBbOfJdt3Y6ibY6un4q6uwZs0aI+Z1ba/jWjO8Ts/r+IA7n4Lr1/BaPY+jbftAe+fYeqww3h//zR07dnS9hq/tpu77FCj+G6dPn27EkZGRRty3b1/rPvv37x/8gZ1BfC1zDszHH3/ses2kSZNO6zGdDvrFRERERDxDExMRERHxDE1MRERExDM0MRERERHPUPJrPXFhnF27dhlx9+7d63w9J7dx8honbnFyqr8iUXXtn5OkDh48aMQHDhxw7aOlNfHjZDrAPU7t2rUzYk5K7NChgxFz0SobTma1Nf2zJWXaCrz5K8DEiZyhhj9LPKb+zknv3r2NmD9/fB3YkpY5AZcLcXGyPCch8zHaCiQy/jzX5zzzNoEmcp9pAwYMMOLs7Gwj5qZ+nPDvD18rp7sZq+3zaWsKykXl+JyWlJS43pOLwIUC/WIiIiIinqGJiYiIiHiGJiYiIiLiGcoxqaepU6caMa8h8xoxFzPitUDOIeHcBd5ffHy8EfOaODd3Ou+884y4W7duRuyvUduoUaNcjzVn3LALcK/Hco4Jr8vzdeCvgNmpAl2ztjUN5FwHPj6+Tvi6BIDly5cHdExeY1un50ZtgDvHhHF+Auds8XvwdcDjzNcFX3uc78S5D7bcJs5x85c39NZbbxkx52x4vYkf5/Fwo0JumFefzxrncDR2TolNsE0/hwwZYsT83wHA3VgwFHj7ShQREZEWRRMTERER8QxNTERERMQzlGNST3yP/AsvvNBERyKNpVOnTq7HsrKyjLigoMCIORcg2KZ+tu15Ddy2vW2NfPDgwa7HXnvttTpf43WcB8T5WRMnTnS9pk+fPnXu09+1EYiuXbsacaDNG3n7QHMhOLcIcDf2O3TokBFzjobXXH311Ua8adOmoPd5pnNKbGzHw8//7W9/O52H02T0i4mIiIh4RkATk1mzZqFv376Ijo5GdHQ00tPT8eGHH/qeP3bsGDIzMxEXF4cOHTpg5MiRroqpIiIiIt8noIlJcnIynnrqKRQWFmL16tW49tprcfPNN2Pjxo0AgClTpmDhwoWYP38+8vLyUFJSghEjRpyWAxcREZHmJ8wJ9MZpEhsbi2eeeQa33norunbtirlz5+LWW28FAHz55Zfo1asX8vPzcfnll9drf5WVlYiJicHvfve7evU6EBERkaZ39OhR/OpXv0JFRQWio6MbvJ8G55icOHEC8+bNw+HDh5Geno7CwkLU1NQgIyPDt03Pnj2RkpKC/Pz8791PdXU1KisrjX8iIiLSMgU8MVm/fj06dOiAyMhI3HPPPViwYAEuuugilJaWIiIiwpXNnpCQUGfX2pycHMTExPj+2br0ioiISPMV8MTkwgsvxLp161BQUIB7770XY8eODeq2rezsbFRUVPj+hWKLZhEREWkcAdcxiYiIwPnnnw8ASEtLw6pVq/CHP/wBt912G44fP47y8nLjV5OysjIkJiZ+7/4iIyP93nMvIiIiLU/QdUxqa2tRXV2NtLQ0tGnTBrm5ub7nioqKsGvXLqSnpwf7NiIiItICBPSLSXZ2NoYNG4aUlBRUVVVh7ty5+PTTT7F48WLExMRg3LhxyMrKQmxsLKKjozFx4kSkp6fX+44cERERadkCmpjs27cPY8aMwd69exETE4O+ffti8eLFuP766wEAzz33HMLDwzFy5EhUV1dj6NCheOmllwI6oJN3L3ObcREREfGuk//dDrIKSfB1TBrb7t27dWeOiIhIiCouLkZycnKDX++5iUltbS1KSkrgOA5SUlJQXFwcVKGWlq6yshLdu3fXOAZBYxg8jWHj0DgGT2MYvO8bQ8dxUFVVhaSkJISHNzyF1XPdhcPDw5GcnOwrtHayL48ER+MYPI1h8DSGjUPjGDyNYfD8jWFMTEzQ+1V3YREREfEMTUxERETEMzw7MYmMjMRjjz2m4mtB0jgGT2MYPI1h49A4Bk9jGLzTPYaeS34VERGRlsuzv5iIiIhIy6OJiYiIiHiGJiYiIiLiGZqYiIiIiGd4dmIyc+ZMnHPOOYiKisKgQYOwcuXKpj4kz8rJycFll12Gjh07Ij4+HrfccguKioqMbY4dO4bMzEzExcWhQ4cOGDlyJMrKyproiL3vqaeeQlhYGCZPnux7TGNYP3v27MEdd9yBuLg4tG3bFn369MHq1at9zzuOg0cffRTdunVD27ZtkZGRga1btzbhEXvLiRMnMG3aNKSmpqJt27Y477zz8Jvf/MboP6IxNC1btgw33ngjkpKSEBYWhvfff994vj7jdfDgQYwePRrR0dHo1KkTxo0bh0OHDp3Bv6Lp1TWONTU1ePDBB9GnTx+0b98eSUlJGDNmDEpKSox9NMY4enJi8vbbbyMrKwuPPfYY1qxZg0suuQRDhw7Fvn37mvrQPCkvLw+ZmZlYsWIFlixZgpqaGtxwww04fPiwb5spU6Zg4cKFmD9/PvLy8lBSUoIRI0Y04VF716pVq/Dyyy+jb9++xuMaQ7tvv/0WgwcPRps2bfDhhx9i06ZNePbZZ9G5c2ffNtOnT8fzzz+P2bNno6CgAO3bt8fQoUPVuPN/nn76acyaNQsvvvgiNm/ejKeffhrTp0/HCy+84NtGY2g6fPgwLrnkEsycOdPv8/UZr9GjR2Pjxo1YsmQJFi1ahGXLlmH8+PFn6k/whLrG8ciRI1izZg2mTZuGNWvW4L333kNRURFuuukmY7tGGUfHgwYOHOhkZmb64hMnTjhJSUlOTk5OEx5V6Ni3b58DwMnLy3Mcx3HKy8udNm3aOPPnz/dts3nzZgeAk5+f31SH6UlVVVVOjx49nCVLljjXXHONM2nSJMdxNIb19eCDDzpXXnnl9z5fW1vrJCYmOs8884zvsfLycicyMtJ56623zsQhet7w4cOdu+++23hsxIgRzujRox3H0RjaAHAWLFjgi+szXps2bXIAOKtWrfJt8+GHHzphYWHOnj17ztixewmPoz8rV650ADg7d+50HKfxxtFzv5gcP34chYWFyMjI8D0WHh6OjIwM5OfnN+GRhY6KigoAQGxsLACgsLAQNTU1xpj27NkTKSkpGlOSmZmJ4cOHG2MFaAzr6+9//zsGDBiAn/zkJ4iPj0f//v3xpz/9yff8jh07UFpaaoxjTEwMBg0apHH8nyuuuAK5ubnYsmULAOA///kPli9fjmHDhgHQGAaqPuOVn5+PTp06YcCAAb5tMjIyEB4ejoKCgjN+zKGioqICYWFh6NSpE4DGG0fPNfE7cOAATpw4gYSEBOPxhIQEfPnll010VKGjtrYWkydPxuDBg9G7d28AQGlpKSIiInwXz0kJCQkoLS1tgqP0pnnz5mHNmjVYtWqV6zmNYf1s374ds2bNQlZWFh566CGsWrUKv/jFLxAREYGxY8f6xsrf51vj+F9Tp05FZWUlevbsiVatWuHEiRN48sknMXr0aADQGAaoPuNVWlqK+Ph44/nWrVsjNjZWY/o9jh07hgcffBCjRo3yNfJrrHH03MREgpOZmYkNGzZg+fLlTX0oIaW4uBiTJk3CkiVLEBUV1dSHE7Jqa2sxYMAA/Pa3vwUA9O/fHxs2bMDs2bMxduzYJj660PDOO+/gzTffxNy5c3HxxRdj3bp1mDx5MpKSkjSG4gk1NTX46U9/CsdxMGvWrEbfv+eWcrp06YJWrVq57nYoKytDYmJiEx1VaJgwYQIWLVqETz75BMnJyb7HExMTcfz4cZSXlxvba0z/X2FhIfbt24dLL70UrVu3RuvWrZGXl4fnn38erVu3RkJCgsawHrp164aLLrrIeKxXr17YtWsXAPjGSp/v73f//fdj6tSpuP3229GnTx/ceeedmDJlCnJycgBoDANVn/FKTEx03Vzx3Xff4eDBgxpTcnJSsnPnTixZssT3awnQeOPouYlJREQE0tLSkJub63ustrYWubm5SE9Pb8Ij8y7HcTBhwgQsWLAAS5cuRWpqqvF8Wloa2rRpY4xpUVERdu3apTH9n+uuuw7r16/HunXrfP8GDBiA0aNH+/63xtBu8ODBrlvVt2zZgrPPPhsAkJqaisTERGMcKysrUVBQoHH8nyNHjiA83PxqbtWqFWprawFoDANVn/FKT09HeXk5CgsLfdssXboUtbW1GDRo0Bk/Zq86OSnZunUrPv74Y8TFxRnPN9o4NiBZ97SbN2+eExkZ6cyZM8fZtGmTM378eKdTp05OaWlpUx+aJ917771OTEyM8+mnnzp79+71/Tty5Ihvm3vuucdJSUlxli5d6qxevdpJT0930tPTm/Cove/Uu3IcR2NYHytXrnRat27tPPnkk87WrVudN99802nXrp3zxhtv+LZ56qmnnE6dOjkffPCB88UXXzg333yzk5qa6hw9erQJj9w7xo4d65x11lnOokWLnB07djjvvfee06VLF+eBBx7wbaMxNFVVVTlr16511q5d6wBwfv/73ztr16713S1Sn/H64Q9/6PTv398pKChwli9f7vTo0cMZNWpUU/1JTaKucTx+/Lhz0003OcnJyc66deuM/9ZUV1f79tEY4+jJiYnjOM4LL7zgpKSkOBEREc7AgQOdFStWNPUheRYAv/9effVV3zZHjx517rvvPqdz585Ou3btnB//+MfO3r17m+6gQwBPTDSG9bNw4UKnd+/eTmRkpNOzZ0/nj3/8o/F8bW2tM23aNCchIcGJjIx0rrvuOqeoqKiJjtZ7KisrnUmTJjkpKSlOVFSUc+655zoPP/yw8eWvMTR98sknfr8Dx44d6zhO/cbrm2++cUaNGuV06NDBiY6Odu666y6nqqqqCf6aplPXOO7YseN7/1vzySef+PbRGOMY5jinlBMUERERaUKeyzERERGRlksTExEREfEMTUxERETEMzQxEREREc/QxEREREQ8QxMTERER8QxNTERERMQzNDERERERz9DERERERDxDExMRERHxDE1MRERExDM0MRERERHP+D+RXATGpz+UOgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# PyTorch models inherit from torch.nn.Module\n",
        "class GarmentClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GarmentClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = GarmentClassifier()"
      ],
      "metadata": {
        "id": "vVCzAWmz3SZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# NB: Loss functions expect data in batches, so we're creating batches of 4\n",
        "# Represents the model's confidence in each of the 10 classes for a given input\n",
        "dummy_outputs = torch.rand(4, 10)\n",
        "# Represents the correct class among the 10 being tested\n",
        "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
        "\n",
        "print(dummy_outputs)\n",
        "print(dummy_labels)\n",
        "\n",
        "loss = loss_fn(dummy_outputs, dummy_labels)\n",
        "print('Total loss for this batch: {}'.format(loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJGV1i9Q3hQu",
        "outputId": "502f6e9c-3eda-447b-8119-b7c481a5ed5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7006, 0.4822, 0.8868, 0.5842, 0.9985, 0.4313, 0.5414, 0.3406, 0.6026,\n",
            "         0.6888],\n",
            "        [0.9262, 0.5191, 0.1010, 0.5353, 0.0364, 0.1251, 0.2849, 0.2800, 0.5409,\n",
            "         0.6426],\n",
            "        [0.1888, 0.3743, 0.7960, 0.4193, 0.0178, 0.0386, 0.6624, 0.9525, 0.2164,\n",
            "         0.1160],\n",
            "        [0.0803, 0.4746, 0.5817, 0.8494, 0.9971, 0.9580, 0.4902, 0.3764, 0.5071,\n",
            "         0.9477]])\n",
            "tensor([1, 5, 3, 7])\n",
            "Total loss for this batch: 2.4955968856811523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizers specified in the torch.optim package\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "sbAUyK9B3wNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(training_loader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss"
      ],
      "metadata": {
        "id": "HDU-Uw7U34e8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "epoch_number = 0\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    model.train(True)\n",
        "    avg_loss = train_one_epoch(epoch_number, writer)\n",
        "\n",
        "    # We don't need gradients on to do reporting\n",
        "    model.train(False)\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    for i, vdata in enumerate(validation_loader):\n",
        "        vinputs, vlabels = vdata\n",
        "        voutputs = model(vinputs)\n",
        "        vloss = loss_fn(voutputs, vlabels)\n",
        "        running_vloss += vloss\n",
        "\n",
        "    avg_vloss = running_vloss / (i + 1)\n",
        "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "    # Log the running loss averaged per batch\n",
        "    # for both training and validation\n",
        "    writer.add_scalars('Training vs. Validation Loss',\n",
        "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                    epoch_number + 1)\n",
        "    writer.flush()\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "    if avg_vloss < best_vloss:\n",
        "        best_vloss = avg_vloss\n",
        "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    epoch_number += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35jsF6dZ4Hlq",
        "outputId": "1b905d19-3a3d-4162-b2d9-2c896498b0af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n",
            "  batch 1000 loss: 1.7052603275626899\n",
            "  batch 2000 loss: 0.8081635039895773\n",
            "  batch 3000 loss: 0.6670757386945187\n",
            "  batch 4000 loss: 0.6398680353057571\n",
            "  batch 5000 loss: 0.6042178578309831\n",
            "  batch 6000 loss: 0.5862486737694708\n",
            "  batch 7000 loss: 0.5466249065340962\n",
            "  batch 8000 loss: 0.534749640013877\n",
            "  batch 9000 loss: 0.5143960502118571\n",
            "  batch 10000 loss: 0.49160817020293324\n",
            "  batch 11000 loss: 0.48073204873199576\n",
            "  batch 12000 loss: 0.4792433746672468\n",
            "  batch 13000 loss: 0.4496018420099281\n",
            "  batch 14000 loss: 0.46419690796965735\n",
            "  batch 15000 loss: 0.43451347304228694\n",
            "LOSS train 0.43451347304228694 valid 0.4276195764541626\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 0.40670005799731007\n",
            "  batch 2000 loss: 0.42502640876325315\n",
            "  batch 3000 loss: 0.41893996040394993\n",
            "  batch 4000 loss: 0.40222991805744823\n",
            "  batch 5000 loss: 0.38450373202422633\n",
            "  batch 6000 loss: 0.41050434745976233\n",
            "  batch 7000 loss: 0.3888735272201593\n",
            "  batch 8000 loss: 0.3739240455732215\n",
            "  batch 9000 loss: 0.38415506149834255\n",
            "  batch 10000 loss: 0.3872066893392475\n",
            "  batch 11000 loss: 0.3734845570070029\n",
            "  batch 12000 loss: 0.34950211874239906\n",
            "  batch 13000 loss: 0.3658386618561926\n",
            "  batch 14000 loss: 0.35420397101924755\n",
            "  batch 15000 loss: 0.35975551312835885\n",
            "LOSS train 0.35975551312835885 valid 0.3984116017818451\n",
            "EPOCH 3:\n",
            "  batch 1000 loss: 0.3410915394994663\n",
            "  batch 2000 loss: 0.352503238723275\n",
            "  batch 3000 loss: 0.3473561357164872\n",
            "  batch 4000 loss: 0.33904231912443356\n",
            "  batch 5000 loss: 0.32240329966888387\n",
            "  batch 6000 loss: 0.3370433406277734\n",
            "  batch 7000 loss: 0.3339950188586372\n",
            "  batch 8000 loss: 0.3304207252532651\n",
            "  batch 9000 loss: 0.35302374102211614\n",
            "  batch 10000 loss: 0.3390267914021242\n",
            "  batch 11000 loss: 0.30482070278038736\n",
            "  batch 12000 loss: 0.32466163650591623\n",
            "  batch 13000 loss: 0.3260052337730012\n",
            "  batch 14000 loss: 0.3189069326032768\n",
            "  batch 15000 loss: 0.3212833148300597\n",
            "LOSS train 0.3212833148300597 valid 0.3734588027000427\n",
            "EPOCH 4:\n",
            "  batch 1000 loss: 0.3096087452454012\n",
            "  batch 2000 loss: 0.2997113937453978\n",
            "  batch 3000 loss: 0.29074216562104993\n",
            "  batch 4000 loss: 0.32019827361930947\n",
            "  batch 5000 loss: 0.30835324847491574\n",
            "  batch 6000 loss: 0.2981822356739212\n",
            "  batch 7000 loss: 0.30468768791835465\n",
            "  batch 8000 loss: 0.28149226627984897\n",
            "  batch 9000 loss: 0.31260842276853507\n",
            "  batch 10000 loss: 0.2973886631241985\n",
            "  batch 11000 loss: 0.32729298463536544\n",
            "  batch 12000 loss: 0.28530038212145153\n",
            "  batch 13000 loss: 0.29057451479534213\n",
            "  batch 14000 loss: 0.3180856289159274\n",
            "  batch 15000 loss: 0.3131979542635299\n",
            "LOSS train 0.3131979542635299 valid 0.3335360288619995\n",
            "EPOCH 5:\n",
            "  batch 1000 loss: 0.27567432053457014\n",
            "  batch 2000 loss: 0.28329844646059793\n",
            "  batch 3000 loss: 0.27902332285183545\n",
            "  batch 4000 loss: 0.2662088112336169\n",
            "  batch 5000 loss: 0.31756132617773253\n",
            "  batch 6000 loss: 0.283856081455644\n",
            "  batch 7000 loss: 0.27360772993513455\n",
            "  batch 8000 loss: 0.30039387901827286\n",
            "  batch 9000 loss: 0.2666177971381403\n",
            "  batch 10000 loss: 0.26333818762220473\n",
            "  batch 11000 loss: 0.30727994722947916\n",
            "  batch 12000 loss: 0.29536736887953885\n",
            "  batch 13000 loss: 0.27828273911431095\n",
            "  batch 14000 loss: 0.27247061024597496\n",
            "  batch 15000 loss: 0.27955026580546566\n",
            "LOSS train 0.27955026580546566 valid 0.32701489329338074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U0WlX7504Rrr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}